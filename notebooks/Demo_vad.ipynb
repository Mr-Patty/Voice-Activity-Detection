{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8627b1a-b397-43b7-9a8b-fec5e278df43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install onnx\n",
    "# !pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36204edf-8f4a-436d-bf5c-5f07101e1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import soundfile as sf\n",
    "\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from webrtc_utils import *\n",
    "    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "from os import walk\n",
    "import math\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "#display waveform\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006f6910-5842-4590-85e0-43e6b9967c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, inpud_dim=40, hidden_dim=64, n_layers=2, dropout=0.5):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(inpud_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc2 = nn.Linear(hidden_dim//2, 1)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MFCC(sample_rate=16000, n_mfcc=40, melkwargs={'win_length':400, 'hop_length':160, \"center\":True, 'n_mels':64}),\n",
    "    torchaudio.transforms.SlidingWindowCmn(cmn_window=300, norm_vars=True, center=True)\n",
    ")\n",
    "   \n",
    "    \n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b9cef1-5483-407c-bf0d-bfcf3a3ceaef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12603/2111914371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Code for recording audio from the browser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJavascript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbase64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Code for recording audio from the browser\n",
    "from IPython.display import Javascript\n",
    "from google.colab import output\n",
    "from base64 import b64decode\n",
    "import IPython\n",
    "import uuid\n",
    "from google.colab import output\n",
    "\n",
    "\n",
    "class InvokeButton(object):\n",
    "  def __init__(self, title, callback):\n",
    "    self._title = title\n",
    "    self._callback = callback\n",
    "\n",
    "  def _repr_html_(self):\n",
    "    from google.colab import output\n",
    "    callback_id = 'button-' + str(uuid.uuid4())\n",
    "    output.register_callback(callback_id, self._callback)\n",
    "\n",
    "    template = \"\"\"<button id=\"{callback_id}\" style=\"cursor:pointer;background-color:#EEEEEE;border-color:#E0E0E0;padding:5px 15px;font-size:14px\">{title}</button>\n",
    "        <script>\n",
    "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
    "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
    "            e.preventDefault();\n",
    "          }};\n",
    "        </script>\"\"\"\n",
    "    html = template.format(title=self._title, callback_id=callback_id)\n",
    "    return html\n",
    "\n",
    "RECORD = \"\"\"\n",
    "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
    "const b2text = blob => new Promise(resolve => {\n",
    "  const reader = new FileReader()\n",
    "  reader.onloadend = e => resolve(e.srcElement.result)\n",
    "  reader.readAsDataURL(blob)\n",
    "})\n",
    "var record = time => new Promise(async resolve => {\n",
    "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
    "  recorder = new MediaRecorder(stream)\n",
    "  chunks = []\n",
    "  recorder.ondataavailable = e => chunks.push(e.data)\n",
    "  recorder.start()\n",
    "  await sleep(time)\n",
    "  recorder.onstop = async ()=>{\n",
    "    blob = new Blob(chunks)\n",
    "    text = await b2text(blob)\n",
    "    resolve(text)\n",
    "  }\n",
    "  recorder.stop()\n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "def record(sec=3):\n",
    "    display(Javascript(RECORD))\n",
    "    s = output.eval_js('record(%d)' % (sec*1000))\n",
    "    b = b64decode(s.split(',')[1])\n",
    "    with open('audio.wav','wb+') as f:\n",
    "        f.write(b)\n",
    "    return 'audio.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ca297-e090-4775-a413-4993914b663f",
   "metadata": {},
   "source": [
    "#### Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8e8e6a-9f80-441b-939c-ed8b55c230bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(40, 64, num_layers=2, batch_first=True)\n",
       "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(inpud_dim=40, hidden_dim=64, n_layers=2, dropout=0.5).float()\n",
    "model.load_state_dict(torch.load('../data/vad.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa521894-ab18-4299-9088-071731534d31",
   "metadata": {},
   "source": [
    "#### Onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04ee08c-5b3a-43a5-af4c-77daa67ba593",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:53: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "if device == 'cuda':\n",
    "    providers = ['CUDAExecutionProvider']\n",
    "else:\n",
    "    providers = ['CPUExecutionProvider']\n",
    "ort_session = onnxruntime.InferenceSession('../data/vad.onnx', providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7efb65e7-dd0e-449b-8184-97baec77509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_torch(wavfile, thr=0.7):\n",
    "    waveform, _ = sf.load(wavfile)\n",
    "    \n",
    "    features = audio_transforms(torch.from_numpy(waveform).float())[:, :-1].transpose(0, 1)\n",
    "    with torch.no_grad():\n",
    "        output = to_numpy(model(torch.unsqueeze(features, 0).float().to(device))).reshape(features.shape[0])\n",
    "    \n",
    "    output = (output > thr).astype(int)\n",
    "    return output\n",
    "\n",
    "def predict_onnx(wavfile):\n",
    "    waveform, _ = sf.load(wavfile)\n",
    "    \n",
    "    features = audio_transforms(torch.from_numpy(waveform).float())[:, :-1].transpose(0, 1)\n",
    "    \n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(torch.unsqueeze(features, 0))}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    output = ort_outs[0].reshape(features.shape[0])\n",
    "    \n",
    "    output = (output > thr).astype(int)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a0506f-be9b-425b-9f57-3f05ba39b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vad(pred, wavfile):\n",
    "    waveform, _ = sf.load(wavfile)\n",
    "    \n",
    "    vad = []\n",
    "    for i in pred:\n",
    "        vad.extend([i] * 160)\n",
    "    vad = np.array(vad)\n",
    "    vad = np.pad(nonspeech, (0, len(waveform) - len(vad)), mode='constant', constant_values=1)[:len(waveform)]\n",
    "    return waveform * vad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10347727-3fe8-48af-afb6-a1caf85828e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,0,1])\n",
    "b = np.array([1,2,3])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39e261-1fb7-4cdb-bbbb-645f9e37f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    print(\"Now recording for 3 seconds, say what you will...\")\n",
    "    record()\n",
    "    os.system('ffmpeg -i audio.wav -ar 16000 -y audio.wav')\n",
    "    pred = predict_onnx('audio.wav')\n",
    "    \n",
    "    amplitudes = apply_vad(pred, 'audio.wav')\n",
    "    IPython.display.Audio(amplitudes, rate = 16000)\n",
    "    \n",
    "\n",
    "InvokeButton('Start recording', predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
